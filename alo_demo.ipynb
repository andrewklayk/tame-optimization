{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from ALOptimizer import ALOptimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x1f285692310>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cuda = False\n",
    "torch.manual_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\andre\\miniconda3\\envs\\hcomp-cuda\\lib\\site-packages\\torchvision\\transforms\\v2\\_deprecated.py:42: UserWarning: The transform `ToTensor()` is deprecated and will be removed in a future release. Instead, please use `v2.Compose([v2.ToImage(), v2.ToDtype(torch.float32, scale=True)])`.Output is equivalent up to float precision.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import torchvision\n",
    "import torchvision.transforms.v2 as transforms\n",
    "\n",
    "dataset = torchvision.datasets.MNIST('/data', download=True, train=True)\n",
    "\n",
    "\n",
    "\n",
    "batch_size = 16\n",
    "\n",
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),])\n",
    "trainset = torchvision.datasets.MNIST('/data', train=True, transform=transform)\n",
    "# trainset = torch.utils.data.\n",
    "trainset = torch.utils.data.Subset(trainset, np.arange(0, 20000))\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size,\n",
    "                                          shuffle=False, num_workers=0,\n",
    "                                          generator=torch.Generator(device='cuda') if cuda else None)\n",
    "\n",
    "testset = torchvision.datasets.MNIST('/data', train=False, transform=transform)\n",
    "\n",
    "true_test, constr_test = torch.utils.data.random_split(testset, [0.95, 0.05])\n",
    "constr_test_loader = torch.utils.data.DataLoader(constr_test, batch_size=batch_size,\n",
    "                                          shuffle=True, num_workers=0,\n",
    "                                          generator=torch.Generator(device='cuda') if cuda else None)\n",
    "true_test_loader = torch.utils.data.DataLoader(true_test, batch_size=batch_size,\n",
    "                                          shuffle=True, num_workers=0,\n",
    "                                          generator=torch.Generator(device='cuda') if cuda else None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self, n_in, n_out):\n",
    "        super(Net, self).__init__()\n",
    "\n",
    "        # 1 input image channel, 6 output channels, 5x5 square convolution\n",
    "        # kernel\n",
    "        self.conv1 = nn.Conv2d(1, 6, 5)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        # an affine operation: y = Wx + b\n",
    "        self.fc1 = nn.Linear(16 * 4 * 4, 120)  # 5*5 from image dimension\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "        # self.double()\n",
    "    \n",
    "    def forward(self, input):\n",
    "\n",
    "        # Convolution layer C1: 1 input image channel, 6 output channels,\n",
    "        # 5x5 square convolution, it uses RELU activation function, and\n",
    "        # outputs a Tensor with size (N, 6, 28, 28), where N is the size of the batch\n",
    "        c1 = F.relu(self.conv1(input))\n",
    "        # Subsampling layer S2: 2x2 grid, purely functional,\n",
    "        # this layer does not have any parameter, and outputs a (N, 6, 14, 14) Tensor\n",
    "        s2 = F.max_pool2d(c1, (2, 2))\n",
    "        # Convolution layer C3: 6 input channels, 16 output channels,\n",
    "        # 5x5 square convolution, it uses RELU activation function, and\n",
    "        # outputs a (N, 16, 10, 10) Tensor\n",
    "        c3 = F.relu(self.conv2(s2))\n",
    "        # Subsampling layer S4: 2x2 grid, purely functional,\n",
    "        # this layer does not have any parameter, and outputs a (N, 16, 5, 5) Tensor\n",
    "        s4 = F.max_pool2d(c3, 2)\n",
    "        # Flatten operation: purely functional, outputs a (N, 400) Tensor\n",
    "        s4 = torch.flatten(s4, 1)\n",
    "        # Fully connected layer F5: (N, 400) Tensor input,\n",
    "        # and outputs a (N, 120) Tensor, it uses RELU activation function\n",
    "        f5 = F.relu(self.fc1(s4))\n",
    "        # Fully connected layer F6: (N, 120) Tensor input,\n",
    "        # and outputs a (N, 84) Tensor, it uses RELU activation function\n",
    "        f6 = F.relu(self.fc2(f5))\n",
    "        # Gaussian layer OUTPUT: (N, 84) Tensor input, and\n",
    "        # outputs a (N, 10) Tensor\n",
    "        output = self.fc3(f6)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "***\n",
    "Try a constraint on the loss on a separate subset of data (stochastic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_loss_constr(net, loss_fn, testset, threshold):\n",
    "    loss = 0\n",
    "    \n",
    "    for i, (inputs, labels) in enumerate(testset):\n",
    "        out = net.forward(inputs)\n",
    "        loss += loss_fn(out, labels)\n",
    "    loss /= i\n",
    "    return torch.max((loss-threshold), torch.zeros(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_classes = 10\n",
    "class_test_net = Net(1, n_classes)\n",
    "loss = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "def constraint(net):\n",
    "    return test_loss_constr(net, loss, constr_test_loader, 0.1)\n",
    "\n",
    "alo = ALOptimizer(net=class_test_net, loss_fn=loss, m=1, constraint_fn=constraint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alo.optimize(trainloader, maxiter=3, epochs=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = 0\n",
    "with torch.no_grad():\n",
    "    for i, data in enumerate(true_test):\n",
    "        inputs, labels = data\n",
    "        out = class_test_net.forward(inputs.unsqueeze(0))\n",
    "        if np.argmax(out.detach().numpy()) == labels:\n",
    "            acc+=1\n",
    "\n",
    "acc/len(true_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    x = test_loss_constr(class_test_net, loss, constr_test_loader, 0)\n",
    "    print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    x = test_loss_constr(class_test_net, loss, true_test_loader, 0)\n",
    "    print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An L2 constraint on the weights. This is a deterministic constraint."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We get\n",
    "\n",
    "$$\n",
    "L := l(outputs, labels) + \\lambda*h(W) + 0.5 \\lambda r * h(W)^2 \n",
    "$$\n",
    "\n",
    "where\n",
    "\n",
    "$$\n",
    "h(W) := \\begin{cases} 0 \\qquad \\textrm{if} \\quad  {||W||_2}^2 - c \\leq 0 \\\\ {||W||_2}^2  \\quad \\textrm{otherwise} \\end{cases}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def total_w_l2_constr(params, c):\n",
    "    l2 = 0\n",
    "    for param in params:\n",
    "        l2 += torch.sum(torch.square(param))\n",
    "    cval = torch.max(l2 - c, torch.zeros(1, dtype=param.dtype))\n",
    "    return cval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_classes = 10\n",
    "class_test_net = Net(1, n_classes)\n",
    "loss = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "def constraint(net):\n",
    "    return total_w_l2_constr(net.parameters(), 15)\n",
    "\n",
    "alo = ALOptimizer(net=class_test_net, loss_fn=loss, m=1, constraint_fn=constraint, lr=0.005)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------, 0.5651281476020813, 0.1545629501342773495\n",
      "\n",
      "\n",
      "-------, 0.4269465506076813, 0.004867286682128906525\n",
      "\n",
      "\n",
      "-------, 0.5182909965515137, 0.0312751770019531255\n",
      "\n",
      "\n",
      "-------, 0.48326167464256287, 0.050935363769531268\n",
      "\n",
      "\n",
      "-------, 0.49779263138771057, 0.086443328857422895\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "alo.optimize(trainloader, maxiter=5, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(14.4275, grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l2 = 0\n",
    "for param in class_test_net.parameters():\n",
    "    l2 += torch.sum(torch.square(param))\n",
    "l2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.744"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc = 0\n",
    "with torch.no_grad():\n",
    "    for i, data in enumerate(true_test):\n",
    "        inputs, labels = data\n",
    "        out = class_test_net.forward(inputs.unsqueeze(0))\n",
    "        if np.argmax(out.detach().numpy()) == labels:\n",
    "            acc+=1\n",
    "\n",
    "acc/len(true_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hcomp-cuda",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
