{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from ALOptimizer import ALOptimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x2797732a630>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cuda = False\n",
    "torch.manual_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision\n",
    "import torchvision.transforms.v2 as transforms\n",
    "\n",
    "dataset = torchvision.datasets.MNIST('/data', download=True, train=True)\n",
    "\n",
    "\n",
    "\n",
    "batch_size = 16\n",
    "\n",
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),])\n",
    "trainset = torchvision.datasets.MNIST('/data', train=True, transform=transform)\n",
    "# trainset = torch.utils.data.\n",
    "trainset = torch.utils.data.Subset(trainset, np.arange(0, 5000))\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size,\n",
    "                                          shuffle=False, num_workers=0,\n",
    "                                          generator=torch.Generator(device='cuda') if cuda else None)\n",
    "\n",
    "testset = torchvision.datasets.MNIST('/data', train=False, transform=transform)\n",
    "\n",
    "true_test, constr_test = torch.utils.data.random_split(testset, [0.95, 0.05])\n",
    "constr_test_loader = torch.utils.data.DataLoader(constr_test, batch_size=batch_size,\n",
    "                                          shuffle=True, num_workers=0,\n",
    "                                          generator=torch.Generator(device='cuda') if cuda else None)\n",
    "true_test_loader = torch.utils.data.DataLoader(true_test, batch_size=batch_size,\n",
    "                                          shuffle=True, num_workers=0,\n",
    "                                          generator=torch.Generator(device='cuda') if cuda else None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self, n_in, n_out):\n",
    "        super(Net, self).__init__()\n",
    "\n",
    "        # 1 input image channel, 6 output channels, 5x5 square convolution\n",
    "        # kernel\n",
    "        self.conv1 = nn.Conv2d(1, 6, 5)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        # an affine operation: y = Wx + b\n",
    "        self.fc1 = nn.Linear(16 * 4 * 4, 120)  # 5*5 from image dimension\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "        # self.double()\n",
    "    \n",
    "    def forward(self, input):\n",
    "\n",
    "        # Convolution layer C1: 1 input image channel, 6 output channels,\n",
    "        # 5x5 square convolution, it uses RELU activation function, and\n",
    "        # outputs a Tensor with size (N, 6, 28, 28), where N is the size of the batch\n",
    "        c1 = F.relu(self.conv1(input))\n",
    "        # Subsampling layer S2: 2x2 grid, purely functional,\n",
    "        # this layer does not have any parameter, and outputs a (N, 6, 14, 14) Tensor\n",
    "        s2 = F.max_pool2d(c1, (2, 2))\n",
    "        # Convolution layer C3: 6 input channels, 16 output channels,\n",
    "        # 5x5 square convolution, it uses RELU activation function, and\n",
    "        # outputs a (N, 16, 10, 10) Tensor\n",
    "        c3 = F.relu(self.conv2(s2))\n",
    "        # Subsampling layer S4: 2x2 grid, purely functional,\n",
    "        # this layer does not have any parameter, and outputs a (N, 16, 5, 5) Tensor\n",
    "        s4 = F.max_pool2d(c3, 2)\n",
    "        # Flatten operation: purely functional, outputs a (N, 400) Tensor\n",
    "        s4 = torch.flatten(s4, 1)\n",
    "        # Fully connected layer F5: (N, 400) Tensor input,\n",
    "        # and outputs a (N, 120) Tensor, it uses RELU activation function\n",
    "        f5 = F.relu(self.fc1(s4))\n",
    "        # Fully connected layer F6: (N, 120) Tensor input,\n",
    "        # and outputs a (N, 84) Tensor, it uses RELU activation function\n",
    "        f6 = F.relu(self.fc2(f5))\n",
    "        # Gaussian layer OUTPUT: (N, 84) Tensor input, and\n",
    "        # outputs a (N, 10) Tensor\n",
    "        output = self.fc3(f6)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "***\n",
    "Try a constraint on the loss of subset of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_loss_constr(net, loss_fn, testset, threshold):\n",
    "    loss = 0\n",
    "    \n",
    "    for i, (inputs, labels) in enumerate(testset):\n",
    "        out = net.forward(inputs)\n",
    "        loss += loss_fn(out, labels)\n",
    "    loss /= i\n",
    "    return torch.max((loss-threshold), torch.zeros(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_classes = 10\n",
    "class_test_net = Net(1, n_classes)\n",
    "loss = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "def constraint(net):\n",
    "    return test_loss_constr(net, loss, constr_test_loader, 0.1)\n",
    "\n",
    "alo = ALOptimizer(net=class_test_net, loss_fn=loss, m=1, constraint_fn=constraint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.])10144695406779647, 0.075935646891593933\n",
      "tensor(0.0010)\n",
      "\n",
      "\n",
      "tensor([0.])9201057921164e-05, 0.0027400493621826112\n",
      "tensor(3.0992e-05)\n",
      "\n",
      "\n",
      "tensor([0.])41950340080075e-05, 0.03191259503364566\n",
      "tensor(2.2842e-05)\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "alo.optimize(trainloader, maxiter=3, epochs=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.0227])\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    x = test_loss_constr(class_test_net, loss, constr_test_loader, 0)\n",
    "    print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.1529])\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    x = test_loss_constr(class_test_net, loss, true_test_loader, 0)\n",
    "    print(x)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hcomp-cuda",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
