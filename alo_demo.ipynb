{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from ALOptimizer import ALOptimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x2bd57d36310>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cuda = False\n",
    "torch.manual_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision\n",
    "import torchvision.transforms.v2 as transforms\n",
    "\n",
    "dataset = torchvision.datasets.MNIST('/data', download=True, train=True)\n",
    "\n",
    "batch_size = 16\n",
    "\n",
    "transform = transforms.Compose(\n",
    "    [transforms.ToImage(),\n",
    "     transforms.ToDtype(torch.float32, scale=True)])\n",
    "trainset = torchvision.datasets.MNIST('/data', train=True, transform=transform)\n",
    "# trainset = torch.utils.data.\n",
    "trainset = torch.utils.data.Subset(trainset, np.arange(0, 20000))\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size,\n",
    "                                          shuffle=False, num_workers=0,\n",
    "                                          generator=torch.Generator(device='cuda') if cuda else None)\n",
    "\n",
    "testset = torchvision.datasets.MNIST('/data', train=False, transform=transform)\n",
    "\n",
    "true_test, constr_test = torch.utils.data.random_split(testset, [0.95, 0.05])\n",
    "constr_test_loader = torch.utils.data.DataLoader(constr_test, batch_size=batch_size,\n",
    "                                          shuffle=False, num_workers=0,\n",
    "                                          generator=torch.Generator(device='cuda') if cuda else None)\n",
    "true_test_loader = torch.utils.data.DataLoader(true_test, batch_size=batch_size,\n",
    "                                          shuffle=False, num_workers=0,\n",
    "                                          generator=torch.Generator(device='cuda') if cuda else None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self, n_in, n_out):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 6, 5)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        self.fc1 = nn.Linear(16 * 4 * 4, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "        # self.double()\n",
    "    \n",
    "    def forward(self, input):\n",
    "        c1 = F.relu(self.conv1(input))\n",
    "        s2 = F.max_pool2d(c1, (2, 2))\n",
    "        c3 = F.relu(self.conv2(s2))\n",
    "        s4 = F.max_pool2d(c3, 2)\n",
    "        s4 = torch.flatten(s4, 1)\n",
    "        f5 = F.relu(self.fc1(s4))   \n",
    "        f6 = F.relu(self.fc2(f5))\n",
    "        output = self.fc3(f6)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "***\n",
    "A constraint on the loss on a separate subset of data. This is a stochastic constraint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_loss_constr(net, loss_fn, testset, threshold):\n",
    "    loss = 0\n",
    "    \n",
    "    for i, (inputs, labels) in enumerate(testset):\n",
    "        out = net.forward(inputs)\n",
    "        loss += loss_fn(out, labels)\n",
    "    if i > 0:\n",
    "        loss /= i\n",
    "    return torch.max((loss-threshold), torch.zeros(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_classes = 10\n",
    "class_test_net = Net(1, n_classes)\n",
    "loss = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "def constraint(net):\n",
    "    return test_loss_constr(net, loss, constr_test_loader, 0.1)\n",
    "\n",
    "alo = ALOptimizer(net=class_test_net, loss_fn=loss, m=1, constraint_fn=constraint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0, 1, 2.299325942993164, 2.272899866104126\r"
     ]
    }
   ],
   "source": [
    "alo.optimize(trainloader, maxiter=3, epochs=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9806315789473684"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc = 0\n",
    "with torch.no_grad():\n",
    "    for i, data in enumerate(true_test):\n",
    "        inputs, labels = data\n",
    "        out = class_test_net.forward(inputs.unsqueeze(0))\n",
    "        if np.argmax(out.detach().numpy()) == labels:\n",
    "            acc+=1\n",
    "\n",
    "acc/len(true_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.0446])\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    x = test_loss_constr(class_test_net, loss, constr_test_loader, 0)\n",
    "    print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.0688])\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    x = test_loss_constr(class_test_net, loss, true_test_loader, 0)\n",
    "    print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An L2 constraint on the weights. This is a deterministic constraint."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We get\n",
    "\n",
    "$$\n",
    "L := l(outputs, labels) + \\lambda*h(W) + 0.5 \\lambda r * h(W)^2 \n",
    "$$\n",
    "\n",
    "where\n",
    "\n",
    "$$\n",
    "h(W) := \\begin{cases} 0 \\qquad \\textrm{if} \\quad  {||W||_2}^2 - c \\leq 0 \\\\ {||W||_2}^2 -c  \\quad \\textrm{otherwise} \\end{cases}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def total_w_l2_constr(params, c):\n",
    "    l2 = 0\n",
    "    for param in params:\n",
    "        l2 += torch.sum(torch.square(param))\n",
    "    cval = torch.max(l2 - c, torch.zeros(1, dtype=param.dtype))\n",
    "    return cval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_classes = 10\n",
    "class_test_net = Net(1, n_classes)\n",
    "loss = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "def constraint(net):\n",
    "    return total_w_l2_constr(net.parameters(), 15)\n",
    "\n",
    "alo = ALOptimizer(net=class_test_net, loss_fn=loss, m=1, constraint_fn=constraint, lr=0.005)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------, 0.5727880597114563, 0.0796251296997070345\n",
      "\n",
      "\n",
      "-------, 0.6938788294792175, 0.0863895416259765645\n",
      "\n",
      "\n",
      "-------, 0.6064719557762146, 0.0888954162597656625\n",
      "\n",
      "\n",
      "-------, 0.6860342025756836, 0.0273464202880859462\n",
      "\n",
      "\n",
      "-------, 0.6928727030754089, 0.0074728012084961262\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "alo.optimize(trainloader, maxiter=5, epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(14.6636, grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l2 = 0\n",
    "for param in class_test_net.parameters():\n",
    "    l2 += torch.sum(torch.square(param))\n",
    "l2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7371578947368421"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc = 0\n",
    "with torch.no_grad():\n",
    "    for i, data in enumerate(true_test):\n",
    "        inputs, labels = data\n",
    "        out = class_test_net(inputs.unsqueeze(0))\n",
    "        if np.argmax(out.detach().numpy()) == labels:\n",
    "            acc+=1\n",
    "\n",
    "acc/len(true_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_classes = 10\n",
    "class_test_net = Net(1, n_classes)\n",
    "loss = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "def constraint(net):\n",
    "    return total_w_l2_constr(net.parameters(), 15)\n",
    "\n",
    "alo = ALOptimizer(net=class_test_net, loss_fn=loss, m=1, constraint_fn=constraint, lr=0.005)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4, 4, 1249, 0.42003297805786133, 0.05862693786621094555\r"
     ]
    }
   ],
   "source": [
    "alo.optimize_cond(trainloader, maxiter=5, epochs=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "***\n",
    "Pytorch L2 regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_classes = 10\n",
    "reg_net = Net(1, n_classes)\n",
    "loss = torch.nn.CrossEntropyLoss()\n",
    "op = torch.optim.Adam(reg_net.parameters(), lr=0.005, weight_decay=1e-2)\n",
    "\n",
    "for epoch in range(5):\n",
    "    for i, data in enumerate(trainloader):\n",
    "        op.zero_grad()\n",
    "        inputs, labels = data\n",
    "        outputs = reg_net(inputs)\n",
    "        loss_eval = loss(outputs, labels)\n",
    "        loss_eval.backward()\n",
    "        op.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(48.7833, grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l2 = 0\n",
    "for param in reg_net.parameters():\n",
    "    l2 += torch.sum(torch.square(param))\n",
    "l2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9395789473684211"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc = 0\n",
    "with torch.no_grad():\n",
    "    for i, data in enumerate(true_test):\n",
    "        inputs, labels = data\n",
    "        out = reg_net(inputs.unsqueeze(0))\n",
    "        if np.argmax(out.detach().numpy()) == labels:\n",
    "            acc+=1\n",
    "\n",
    "acc/len(true_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "***\n",
    "profiling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.profiler import profile, record_function, ProfilerActivity\n",
    "\n",
    "with profile(activities=[ProfilerActivity.CPU], record_shapes=True) as prof:\n",
    "    with record_function(\"model_inference\"):\n",
    "        total_w_l2_constr(class_test_net.parameters(), 15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                   Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg    # of Calls  \n",
      "-----------------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "        model_inference        50.87%       1.959ms       100.00%       3.851ms       3.851ms             1  \n",
      "           aten::square         5.67%     218.400us        21.42%     824.800us      82.480us            10  \n",
      "              aten::pow        15.58%     600.100us        15.75%     606.400us      60.640us            10  \n",
      "              aten::sum        13.14%     505.900us        13.54%     521.600us      52.160us            10  \n",
      "              aten::add         0.61%      23.600us        11.58%     446.000us     446.000us             1  \n",
      "               aten::to         5.12%     197.000us        11.36%     437.300us      36.442us            12  \n",
      "         aten::_to_copy         5.75%     221.300us         6.24%     240.300us     120.150us             2  \n",
      "             aten::add_         1.38%      53.300us         1.38%      53.300us       5.922us             9  \n",
      "              aten::sub         0.20%       7.700us         0.51%      19.500us      19.500us             1  \n",
      "              aten::max         0.08%       3.200us         0.39%      15.000us      15.000us             1  \n",
      "-----------------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "Self CPU time total: 3.851ms\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(prof.key_averages().table(sort_by=\"cpu_time_total\", row_limit=10))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hcomp-cuda",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
